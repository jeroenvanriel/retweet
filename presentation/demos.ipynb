{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Post Reply\n",
    "\n",
    "This project focuses on a tool that analyses the sentiment of the tweet and aditionally also predicts what would the sentiments be like of the comments or reply that a tweet is likely to get. It basically predicts the most prbobale sentiment of the comments a tweet can get. We have a sentiment classifier that is trained from the datasets from SemEval-2105 as discussed in the slides earlier. This classifier is so far classifying the sentiments of the tweets fairly correct(we can also remove this line)\n",
    "\n",
    "\n",
    "\n",
    "## We can see a demo of how it classifies the sentiment of tweets below in the code blocks\n",
    "\n",
    "At first we start with extracting tweets using the tweeter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can use the tweeter extraction function and lets extract may be 5 tweets and put them in a list to use it later\n",
    "\n",
    "# from our_tweet_streamer import *\n",
    "# tweet_list = get_tweets(tweet_topic = \"Brexit\", count = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below our trained sentiment classifer is used to predict the sentiments of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code block should be added here where we just predict the sentiments of tweets \n",
    "# we can use our trained saved model and \n",
    "\n",
    "# use the tweet from tweets_list\n",
    "\n",
    "#for tweet in tweet_list:\n",
    "#    sentiment = predict(tweet)\n",
    "#    print(tweet, sentiment)\n",
    "\n",
    "\n",
    "\n",
    "# we can discuss how well it has classified the sentiments from the print statements\n",
    "#(lets hope we have many most correct prediction)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employing the trained Sentiment classifier as a data generation pipeline\n",
    "Classifying only the sentiments of tweets is not just the only goal of the project. We have to predict the  sentiments of the comments to a tweet. For this purpose we use our previously trained sentiment classifier to label the tweets according to the sentiments of its replies/comments. So we use our sentiment-analyser to create the dataset for the next part of the project that is post reply datasets.\n",
    "\n",
    "As discussed in the slides we extract all the replies of the tweet and represent it on a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block to extract the replies of a tweet and accomodating them in a list \n",
    "\n",
    "# this is just a demo of how we are creating our datasets for the second part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have succesfully extracted the tweets and thier replies. Now we apply our trained model to classify the sentiments of each replies and keep them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block to classify the sentiment of the tweet and storing them in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose a label for the respective which would be \"Positive\", \"Negative\", \"Neutral\". The label for a tweet would mean that it would most likely get a positve reply if the label is \"Positive\" and so on. The label for the tweet will be the most repeated sentiments from the sentiments list of the comment to that tweet which is the argmax value of the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block to show how the label for a particular tweet is chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we label all the tweets we have extracted (or  the tweet reply data set obtained from this other group) and get a dataset to train another network for the second part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model for the Post Reply datasets\n",
    "\n",
    "\n",
    "---- information needed to be added ------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
