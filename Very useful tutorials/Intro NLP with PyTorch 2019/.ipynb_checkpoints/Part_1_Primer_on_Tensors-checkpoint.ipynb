{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGHqGiwMcP1c"
   },
   "source": [
    "## Part 1 - Primer on Tensors for Deep Learning using PyTorch\n",
    "\n",
    "**Required Time: 20 minutes**\n",
    "\n",
    "In this notebook, we will cover the basic tensor operations which are useful when implementing and training deep learning models. This guide should provide you with enough background on some of the most important tensor operations and computations used in deep learning and machine learning. This will form the foundation for implementing your NLP models. The focus of this notebook will be on use of PyTorch's high-level APIs, but it will provide insights and concise details where necessary to help the reader. \n",
    "\n",
    "\n",
    "After completing this guide, and with enough practise, the learner should feel comfortable with basic tensor creation/manipulation, and composing a pipeline of tensor operations, which will become useful when implimenting deep learning models with PyTorch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6N6q4aFfz7d"
   },
   "source": [
    "### Journey\n",
    "- What is a tensor?\n",
    "- Building Tensors\n",
    "- Special Tensors\n",
    "- Tensor Properties\n",
    "- Tensor Slicing\n",
    "- Tensor operations and transformations\n",
    "- Cuda Tensors\n",
    "- Pipeline of Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNtf0dChg17G"
   },
   "source": [
    "### What is a Tensor?\n",
    "In different fields and studies, tensors mean completely different things. In the deep learning world, tensors are just high-dimensional data structures which allow for efficient storage and operations. Why are they important? Well, when we are dealing with different kinds of data, such as text and images, we need to *numericalize* (convert to numbers) the data. This means our data will eventually need to be converted into numerical format using some conversion technique. That's not important here. The important part is that tensors store data and we need to learn some properties and chacteristics of them before understanding their use and applicability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qw-tbPDfrhO"
   },
   "outputs": [],
   "source": [
    "# Let's important pytorch -- the main PyTorch library;\n",
    "# already installed for us on the Colab environment\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bxj_hpLaqhTJ"
   },
   "source": [
    "### Building Tensors\n",
    "In deep learning, we are mostly dealing with Tensors. Therefore, it's important to understand different concepts about tensors, such as types, size, special tensors, etc. Let's briefly review a few concepts related to building tensors. Pay close attention to the comments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sibtlo7O0F_a",
    "outputId": "746f2538-4054-40f8-94c7-5407042ff744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# a scalar\n",
    "A = torch.tensor(1)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DJtujitg1aW4",
    "outputId": "022e61a6-bc24-4859-e5c3-ce35b90fb3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# a vector (1D tensor); 3-dimensional vector\n",
    "A = torch.tensor([1,2,3])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EcligP_719GG",
    "outputId": "a5a2d058-cba9-40ce-ebaa-8ed77502c0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# a matrix (2D tensor)\n",
    "A = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8]])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "DCpmGUcF7x1P",
    "outputId": "69c368a0-c730-4218-c15b-3091942a15a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3, 4],\n",
      "         [5, 6, 7, 8]],\n",
      "\n",
      "        [[1, 2, 3, 4],\n",
      "         [5, 6, 7, 8]]])\n",
      "torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# a matrix (3D tensor)\n",
    "A = torch.tensor([[[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8]],\n",
    "                  [[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8]],\n",
    "                 ])\n",
    "print(A)\n",
    "print(A.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VkAWvrAL8dNs",
    "outputId": "b9834c55-d6dd-4482-d365-5d6cb63a8344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2874, 0.0514, 0.2712]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# build tensor from a numpy array; useful for data transformations\n",
    "import numpy as np\n",
    "A = torch.tensor(np.random.rand(1, 3))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCONgneoxmb0"
   },
   "source": [
    "----\n",
    "\n",
    "### Exercise - Constructing Tensor\n",
    "\n",
    "Build a PyTorch tensor usiong a list from 1-10. Hint: use `range(...)`.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_COGZijyR4i"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQBzNWiL8hm4"
   },
   "source": [
    "### Special Tensors\n",
    "\n",
    "We can also build special tensors such as all-zeros matrix, all-ones matrix, already offered by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "zGS4eV4AAQ7r",
    "outputId": "f8296741-c400-4548-902b-064e4441c2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# builing tensor with zeros\n",
    "A = torch.zeros(5, 4, dtype=torch.long)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "H3GKEwLWloQI",
    "outputId": "b203fe4a-0edd-4b4c-d43e-ad5b01d41d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# All-ones matrix\n",
    "A = torch.ones(5, 4)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ncH6YoYJlyG-",
    "outputId": "d74bac39-5c78-4c93-90a7-9d774670535e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# diagonal matrix\n",
    "A = torch.eye(5, 5)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "t7bne3obAi4X",
    "outputId": "19cb76d1-c507-4e58-fa09-b198ab549422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2259, 0.0250, 0.0473, 0.5494],\n",
      "        [0.7806, 0.1233, 0.4988, 0.1047],\n",
      "        [0.9699, 0.4446, 0.8159, 0.6791],\n",
      "        [0.9325, 0.4231, 0.2701, 0.3718],\n",
      "        [0.5849, 0.3372, 0.8695, 0.1236]])\n"
     ]
    }
   ],
   "source": [
    "# building tensors with random information\n",
    "A = torch.rand(5, 4)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xnZRC1udy-lJ",
    "outputId": "f3b08f78-8716-462e-f738-ff27d9cf92c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# like another tensor\n",
    "A = torch.rand(5, 4)\n",
    "\n",
    "B = torch.ones_like(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4ntGiWZ0zaPR",
    "outputId": "d3271e33-529f-4df0-d05a-9b09331778e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-dimensional ranges\n",
    "\n",
    "torch.linspace(3, 10, steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrwEaXtbz508"
   },
   "source": [
    "----\n",
    "\n",
    "### Exercise - Constructing Tensor\n",
    "\n",
    "It's important to familiarize oneself with the [PyTorch documentation](https://pytorch.org/docs/stable/torch.html). To make this obvious, let try to construct a tensor tensor with the list of numbers from 1-10. There is an easy way: use `linspace(...)` shown above.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVjwZln9zvWZ"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IEd6VCM1_li"
   },
   "source": [
    "### Tensor Properties\n",
    "We can check different properties of the tensors we are building. These special functions are helpful to observe the properties of the tensor data structure we are operating on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Tnica0Q_2VCC",
    "outputId": "ab0784c3-e481-444e-f58b-07c8f6e4ad50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# type\n",
    "A = torch.randn(size = (2,3), dtype = torch.float32)\n",
    "print(A.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IsKdV-kF5D4x",
    "outputId": "4f343b12-a93b-4739-b9f7-f98f28238fd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size and view and their difference\n",
    "A = torch.eye(4,5)\n",
    "A.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lq7_ZXdt7D0M"
   },
   "source": [
    "The best way to learn and memorize all these properties is to go into the documentation and practice as much as you can. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAc0YMrIn-ya"
   },
   "source": [
    "### Tensor Slicing\n",
    "Understanding how to query and slice tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "VLS-s-VdoEtX",
    "outputId": "48116ab7-1523-411c-f368-3639081ba3f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n",
      "\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "A =  torch.eye(5, 5)\n",
    "\n",
    "print(A[3:]) # specific row, all columns\n",
    "print(\"\\n\")\n",
    "print(A[: 3]) # slice of rows, all columns\n",
    "print(\"\\n\")\n",
    "print(A[: -1]) # from first row to second to last row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEBUDH_62Xgg"
   },
   "source": [
    "### Tensor Operations and Transformations\n",
    "\n",
    "Times, \n",
    "element-wise multiplication,\n",
    "to.tensor() etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5Ytohwa5xBrX",
    "outputId": "c7601819-d1e0-41c4-85fe-4d4a919cbf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# modify tensor content\n",
    "A = torch.ones(5, 4)\n",
    "\n",
    "A[:2] = 0\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "-Jy3-k2s8DbI",
    "outputId": "cd431274-0460-4ecd-eebc-507b5049b376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "A.transpose(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-EzCcbY8zGd"
   },
   "source": [
    "What happens if we print A again, woud it be transposed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "L_cSLrSY85Tr",
    "outputId": "a9a51814-2a85-4aa3-bb50-a0a6c6dea9d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qQRc5CI89f-"
   },
   "source": [
    "Apparently not! There is a quick fix to make transformations and operations in place. Use \"`_`\" after the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "qmlPNpXX9NW0",
    "outputId": "3de387ff-926c-468f-f45c-240268a46204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "A.transpose_(1, 0)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCHd0Dmn9Uhx"
   },
   "source": [
    "Let's do some simple math..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "VBlyBt-b34Z2",
    "outputId": "b654fb54-1aa2-4e61-9b8b-6c47f8a470a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition\n",
    "A = torch.ones(5, 3)\n",
    "B = torch.ones(5, 3)\n",
    "print(A + B)\n",
    "\n",
    "# addition in place\n",
    "print(torch.add(A, B))\n",
    "\n",
    "# addition in place; uses symbol \"_\"\n",
    "A.add_(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oyF3al0glGjB",
    "outputId": "fedcd4c7-c075-43d1-e6a5-35f310f680d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# power and sum\n",
    "A =  torch.tensor([1.0, 2.0])\n",
    "out = A.pow(2).sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "WSFRAPgJA6ZA",
    "outputId": "0fae1711-5a07-425a-db7f-8bad94811ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "\n",
    "A = torch.eye(5, 5)\n",
    "B = torch.ones(5, 5)\n",
    "\n",
    "print(A * B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmY8ebff96Ts"
   },
   "source": [
    "---\n",
    "\n",
    "### EXERCISE - Tensor Operations and Transformations\n",
    "\n",
    "Generate this matrix (Hint: `torch.rot90()`):\n",
    "\n",
    "```python\n",
    "\n",
    "tensor([[0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 1., 0.],\n",
    "        [0., 0., 1., 0., 0.],\n",
    "        [0., 1., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0.]])\n",
    "```\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmOD9YmsBYHm"
   },
   "outputs": [],
   "source": [
    "A = torch.eye(5, 5)\n",
    "B = torch.ones(5, 5)\n",
    "C = A * B\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "resZM-38ozaY"
   },
   "source": [
    "### Cuda Tensors\n",
    "PyTorch provides the option to easily manipulate tensors in addition to moving them from gpu and cpu, which allows for ease of training and controlling which parts should be commited to the gpu or the cpu. This gives the control/flexibility to the programmer to design the models for different scenarios with different compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "o1wgOhdDqIGw",
    "outputId": "245bf374-7e4f-4d16-d6ec-91cef3fc245d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Cuda status: True\n",
      "---------------------------------------------------\n",
      "Tensor y is stored in:  cuda:0\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "---------------------------------------------------\n",
      "Tensor x is stored in:  cpu\n",
      "tensor([[0.5155, 0.3415, 0.0959],\n",
      "        [0.2833, 0.8981, 0.5401]])\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available in your computer\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Cuda status:\", torch.cuda.is_available())\n",
    "\n",
    "device_0 = torch.device(\"cuda\")\n",
    "device_1 = torch.device(\"cpu\")\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "x = torch.rand(2, 3)\n",
    "y = torch.ones_like(x, device=device_0)\n",
    "z = torch.zeros_like(x, device=device_1)\n",
    "print(\"Tensor y is stored in: \", y.device)\n",
    "print(y)\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Tensor x is stored in: \", x.device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "X4UIvD41D7y1",
    "outputId": "b54ad5df-5083-4846-9f0b-693ed43428c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if tensor stored in GPU\n",
    "\n",
    "print(y.is_cuda)\n",
    "print(x.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OA9DBbSNEOZ6"
   },
   "source": [
    "There are significant differences in execution time when dealing with huge tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EIxsYV92wTXq",
    "outputId": "bf707688-a3e2-4409-bcb2-f1ba190e976a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.7 ms, sys: 1.1 ms, total: 46.8 ms\n",
      "Wall time: 47.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = torch.rand(1000, 1000)\n",
    "b = torch.rand(1000, 1000)\n",
    "\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hK1lt3Cbw18r",
    "outputId": "dfb61f6a-99a0-40d7-a72a-8828ac43b4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 ms, sys: 1.17 ms, total: 18.7 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = torch.rand(1000, 1000).cuda()\n",
    "b = torch.rand(1000, 1000).cuda()\n",
    "\n",
    "a.matmul(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jK0gyWt3A7IA"
   },
   "source": [
    "### Pipeline of Tensor Operations\n",
    "With PyTorch everything is a chain of operations  and the high-level APIs offer all the necessary functionalities to achieve this. Below, we will explore a simple approach to chaining tensor operations. In other words, we are designing a graph or a flow of operations that are chained together, designed to output something. This is essential for training neural networks. This is why neural networks are sometimes called **computation graphs**, because they are simply a chain of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igM7sZfpvPw2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Chain(nn.Module):\n",
    "  def __init__(self, ):\n",
    "    super(Chain, self).__init__()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"X:\")\n",
    "    print(x)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"X powered by 2:\")\n",
    "    print(x.pow(2))\n",
    "    print(\"mean(X): \")\n",
    "    out = x.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "tYWSp6yBv_HE",
    "outputId": "e66b9255-fef2-4dc1-969c-1ee0b7e0c6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "X:\n",
      "tensor([[4.7131e-01, 4.2154e-02, 7.6620e-04, 1.4177e-01, 2.1020e-02],\n",
      "        [5.3419e-02, 2.2027e-01, 9.2426e-01, 2.5027e-01, 8.3245e-01],\n",
      "        [5.2839e-01, 9.2095e-01, 9.5120e-01, 9.4880e-01, 7.9236e-01],\n",
      "        [6.1429e-01, 8.8064e-01, 4.6491e-01, 5.8703e-01, 3.9816e-01]],\n",
      "       dtype=torch.float64)\n",
      "---------------------------------------------------\n",
      "X powered by 2:\n",
      "tensor([[2.2214e-01, 1.7769e-03, 5.8706e-07, 2.0098e-02, 4.4184e-04],\n",
      "        [2.8536e-03, 4.8519e-02, 8.5426e-01, 6.2637e-02, 6.9297e-01],\n",
      "        [2.7919e-01, 8.4816e-01, 9.0478e-01, 9.0022e-01, 6.2783e-01],\n",
      "        [3.7735e-01, 7.7552e-01, 2.1614e-01, 3.4460e-01, 1.5853e-01]],\n",
      "       dtype=torch.float64)\n",
      "mean(X): \n",
      "tensor(0.5022, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x =  torch.rand((4,5), dtype=torch.float64)\n",
    "chain = Chain()\n",
    "mean_x = chain(x)\n",
    "print(mean_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Zs27euryhd4"
   },
   "source": [
    "The benefit of the chainer or computation graph is that it can resused and different inputs can be fed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "0yxO9LJc0Ftw",
    "outputId": "567c6d06-e38c-4d9b-bd87-e0a11115d9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2000)\n",
      "---------------------------------------------------\n",
      "X:\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "---------------------------------------------------\n",
      "X powered by 2:\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "mean(X): \n",
      "tensor(0.2000)\n"
     ]
    }
   ],
   "source": [
    "y = torch.eye(5,5)\n",
    "print(torch.mean(y))\n",
    "chain_2 = Chain()\n",
    "mean_y = chain_2(y)\n",
    "print(mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mH86fmXtVx7p"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Y96xpQoD1jf"
   },
   "source": [
    "### References\n",
    "- [GitHub repo](https://github.com/omarsar/nlp_pycon)\n",
    "- [PyTorch official documentation](https://pytorch.org/docs/stable/tensors.html)\n",
    "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
    "- [Deep Learning Emotion Recognition with PyTorch](https://github.com/omarsar/appworks_meetup_2018/blob/master/Deep%20Learning%20Emotion%20Recognition%20PyTorch.ipynb)\n",
    "- [Hacking Neural Networks](https://colab.research.google.com/drive/1Loc882hPQwhq212TS4bpUYsTF7KZUD9x#scrollTo=xeRo4GLruC72)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Part 1 - Primer on Tensors",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
